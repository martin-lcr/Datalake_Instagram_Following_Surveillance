# Guide d'int√©gration du Quality Tracking

## üéØ Objectif

Am√©liorer la d√©tection des nouveaux followings en tenant compte de la qualit√©/compl√©tude des scrapings pour √©viter les faux positifs lors de scrapings incomplets.

**Nouveaut√© ‚ú®** : Le syst√®me extrait automatiquement le **nombre total r√©el de followings** directement depuis Instagram (valeur affich√©e sur le profil) et l'utilise comme r√©f√©rence pour calculer des scores de compl√©tude pr√©cis.

## üìã √âtapes d'installation

### 1. Lancer le script d'installation automatique

```bash
# Depuis la racine du projet
cd scripts
./install_quality_tracking.sh
```

**Ce script va automatiquement** :
- ‚úÖ Cr√©er les tables et fonctions SQL dans PostgreSQL
- ‚úÖ Migrer les donn√©es historiques existantes
- ‚úÖ Recalculer les scores de compl√©tude
- ‚úÖ Tester le syst√®me avec le tracker Python

**Alternative manuelle** (si vous pr√©f√©rez) :
```bash
# Se connecter au container PostgreSQL
docker exec -i instagram-postgres psql -U airflow -d airflow < sql/create_scraping_metadata.sql
docker exec -i instagram-postgres psql -U airflow -d airflow < sql/detect_truly_new_followings.sql
```

### 2. Modifier le pipeline Python

Dans `scripts/instagram_scraping_ml_pipeline.py`, ajouter apr√®s l'import des modules :

```python
from scraping_quality_tracker import ScrapingQualityTracker
from datetime import datetime
import time

# Configuration PostgreSQL
POSTGRES_CONFIG = {
    'host': 'postgres',
    'port': '5432',
    'database': 'airflow',
    'user': 'airflow',
    'password': 'airflow'
}
```

### 3. Ajouter le tracking apr√®s chaque scraping

Localiser la section o√π les donn√©es sont √©crites dans PostgreSQL (environ ligne 630), et ajouter APR√àS :

```python
# ============================================================================
# √âTAPE 11 : ENREGISTRER LA QUALIT√â DU SCRAPING
# ============================================================================

try:
    print("=" * 80)
    print("√âTAPE 11 : ENREGISTREMENT QUALIT√â SCRAPING")
    print("=" * 80)

    tracker = ScrapingQualityTracker(POSTGRES_CONFIG)

    # Compter le nombre de followings scrap√©s
    scraping_count = df_spark.count()

    # Enregistrer avec m√©tadonn√©es (inclut instagram_reported_total automatiquement)
    completeness_score, is_complete = tracker.record_scraping(
        target_account=normalized_username,
        scraping_date=datetime.now(),
        total_followings=scraping_count,
        scraping_duration_seconds=int(time.time() - start_time) if 'start_time' in locals() else None,
        instagram_reported_total=instagram_reported_total,  # ‚ú® NOUVEAU: Valeur extraite depuis Instagram
        notes=f"Multipass scraping V2 - {scraping_count} followings captured"
    )

    # Afficher le r√©sultat
    status_icon = "‚úÖ" if is_complete else "‚ö†Ô∏è"
    print(f"{status_icon} Score de qualit√©: {completeness_score:.1f}%")
    print(f"{status_icon} Scraping {'COMPLET' if is_complete else 'INCOMPLET'}")

    # Si scraping incomplet, avertir
    if not is_complete:
        print(f"‚ö†Ô∏è  ATTENTION: Ce scraping est incomplet ({completeness_score:.1f}%)")
        print(f"   Les comparaisons utiliseront le dernier scraping complet comme r√©f√©rence")

    # Obtenir les VRAIS nouveaux followings (si scraping complet)
    if is_complete:
        truly_new = tracker.get_truly_new_followings(
            target_account=normalized_username,
            scraping_date=datetime.now()
        )

        print(f"üÜï Vrais nouveaux followings d√©tect√©s: {len(truly_new)}")
        if truly_new:
            print(f"   Premiers nouveaux:")
            for following in truly_new[:5]:
                print(f"     - @{following['username']} ({following['full_name'] or 'N/A'})")

    print("‚úÖ Qualit√© du scraping enregistr√©e avec succ√®s")

except Exception as e:
    print(f"‚ö†Ô∏è  Erreur enregistrement qualit√© (non-bloquant): {e}")
    # Ne pas bloquer le pipeline si le tracking √©choue

print("=" * 80)
```

### 4. Ajouter un chrono au d√©but du script

Au tout d√©but de la fonction `main()` ou du script, ajouter :

```python
start_time = time.time()
```

## üîß Modifications du Dashboard

### Nouvelle API pour les vrais nouveaux

Dans `dashboard/app.py`, ajouter :

```python
@app.route('/api/account/<account_name>/truly-new')
def api_truly_new_followings(account_name):
    """API: Vrais nouveaux followings (robuste aux scrapings incomplets)"""
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'Database connection failed'}), 500

    try:
        cursor = conn.cursor(cursor_factory=RealDictCursor)

        # Param√®tre de date optionnel
        date_filter = request.args.get('date', None)

        if date_filter:
            query = """
            SELECT * FROM get_new_followings_for_date(%s, %s)
            """
            cursor.execute(query, (account_name, date_filter))
        else:
            # Derni√®re date compl√®te
            query = """
            SELECT * FROM get_new_followings_for_date(
                %s,
                (SELECT MAX(scraping_date) FROM scraping_metadata
                 WHERE target_account = %s AND is_complete = TRUE)
            )
            """
            cursor.execute(query, (account_name, account_name))

        results = []
        for row in cursor.fetchall():
            results.append({
                'username': row[0],
                'full_name': row[1],
                'predicted_gender': row[2],
                'is_truly_new': row[3],
                'confidence_score': float(row[4]) if row[4] else 0.0
            })

        cursor.close()
        conn.close()

        return jsonify({
            'success': True,
            'account': account_name,
            'truly_new': results,
            'count': len(results)
        })

    except Exception as e:
        logger.error(f"Erreur API truly_new: {e}")
        if conn:
            conn.close()
        return jsonify({'error': str(e)}), 500


@app.route('/api/scraping-quality/<account_name>')
def api_scraping_quality(account_name):
    """API: Qualit√© des scrapings pour un compte"""
    conn = get_db_connection()
    if not conn:
        return jsonify({'error': 'Database connection failed'}), 500

    try:
        cursor = conn.cursor(cursor_factory=RealDictCursor)

        query = """
        SELECT
            scraping_date,
            total_followings,
            completeness_score,
            is_complete,
            scraping_duration_seconds,
            notes
        FROM scraping_metadata
        WHERE target_account = %s
        ORDER BY scraping_date DESC
        LIMIT 30
        """

        cursor.execute(query, (account_name,))
        quality_history = cursor.fetchall()

        # Formater les dates
        for row in quality_history:
            if row['scraping_date']:
                row['scraping_date'] = row['scraping_date'].strftime('%Y-%m-%d')

        cursor.close()
        conn.close()

        return jsonify({
            'success': True,
            'account': account_name,
            'quality_history': quality_history
        })

    except Exception as e:
        logger.error(f"Erreur API quality: {e}")
        if conn:
            conn.close()
        return jsonify({'error': str(e)}), 500
```

## üìä Exemple d'utilisation

### Dans le terminal

```python
from scraping_quality_tracker import ScrapingQualityTracker
from datetime import datetime

postgres_config = {
    'host': 'postgres',
    'port': '5432',
    'database': 'airflow',
    'user': 'airflow',
    'password': 'airflow'
}

tracker = ScrapingQualityTracker(postgres_config)

# Comparer intelligemment 22/11 vs 24/11
comparison = tracker.compare_scrapings(
    target_account='mariadlaura',
    date1=datetime(2025, 11, 22),
    date2=datetime(2025, 11, 24)
)

print(f"Ajout√©s: {comparison['added_count']}")
print(f"Confiance: {comparison['confidence']}")

# Obtenir le dernier scraping complet
last_complete = tracker.get_last_complete_scraping('mariadlaura')
print(f"Dernier scraping complet: {last_complete['scraping_date']}")
print(f"Total: {last_complete['total_followings']} followings")
```

## üé® Avantages de cette approche

### ‚úÖ R√©sout le probl√®me des scrapings incomplets

- **Avant**: 663 ‚Üí 505 ‚Üí 651 = D√©tecte 146 "ajouts" fant√¥mes
- **Apr√®s**: Compare seulement les scrapings "complets" (score ‚â• 90%)
  - 663 (complet) ‚Üí 651 (complet) = D√©tecte seulement les VRAIS changements

### ‚úÖ Fournit un niveau de confiance

- **High**: Les deux scrapings sont ‚â• 95% complets
- **Medium**: Les deux scrapings sont ‚â• 80% complets
- **Low**: Au moins un scraping < 80% complet

### ‚úÖ Tra√ßabilit√© compl√®te

- Historique de qualit√© de tous les scrapings
- Notes pour documenter les probl√®mes (cookies expir√©s, etc.)
- Dur√©e de scraping track√©e

### ‚úÖ R√©trocompatible

- Les anciennes API continuent de fonctionner
- Les nouvelles API (`/truly-new`, `/scraping-quality`) sont additionnelles
- Si le tracking √©choue, le pipeline continue (non-bloquant)

## üöÄ Migration des donn√©es existantes

Pour remplir la table `scraping_metadata` avec l'historique existant :

```sql
INSERT INTO scraping_metadata (
    target_account,
    scraping_date,
    scraping_timestamp,
    total_followings,
    completeness_score,
    is_complete
)
SELECT
    target_account,
    aggregation_date::date as scraping_date,
    MAX(scraped_at) as scraping_timestamp,
    COUNT(DISTINCT username) as total_followings,
    100.0 as completeness_score,  -- On suppose que les anciens sont complets
    TRUE as is_complete
FROM final_aggregated_scraping
WHERE aggregation_date IS NOT NULL
GROUP BY target_account, aggregation_date::date
ON CONFLICT (target_account, scraping_date, scraping_timestamp) DO NOTHING;
```

Ensuite, recalculer les scores de compl√©tude :

```sql
UPDATE scraping_metadata sm
SET completeness_score = calculate_completeness_score(sm.target_account, sm.total_followings),
    is_complete = (completeness_score >= 90.0);
```

---

## ‚ú® Extraction automatique du nombre total Instagram

### üéØ Fonctionnement

Le syst√®me extrait **automatiquement** le nombre total de followings directement depuis la page profil Instagram (valeur affich√©e comme "357 suivi(e)s") **avant** d'ouvrir la modal de scraping.

### üìç Localisation dans le code

La fonction `extract_instagram_reported_total()` est appel√©e dans `instagram_scraping_ml_pipeline.py` :

```python
# scripts/instagram_scraping_ml_pipeline.py - Lignes 340-344

# Extraire le nombre total report√© par Instagram (avant d'ouvrir la modal)
instagram_reported_total = None
if pass_number == 1:  # Extraire seulement √† la premi√®re passe
    print("üìä Extraction du nombre total depuis Instagram...")
    instagram_reported_total = extract_instagram_reported_total(driver, username)
```

### üîß M√©thodes d'extraction (3 fallbacks)

La fonction utilise 3 m√©thodes avec fallback automatique :

1. **M√©thode XPath** : Recherche via XPath le lien contenant `/following/`
2. **M√©thode Text Search** : Recherche le texte "suivi(e)s" dans la page
3. **M√©thode JavaScript** ‚úÖ : Parse le DOM avec JavaScript (la plus fiable)

**Exemple de sortie** :
```
üìä Extraction du nombre total depuis Instagram...
   ‚ö†Ô∏è  M√©thode 1 √©chou√©e: invalid literal for int() with base 10: '357following'
‚úÖ Instagram reported total extrait (JavaScript): 357 followings
```

### üìä Utilisation dans le calcul de compl√©tude

Le `ScrapingQualityTracker` utilise cette valeur comme **r√©f√©rence prioritaire** :

```python
# scripts/scraping_quality_tracker.py - Lignes 57-66

if instagram_reported_total and instagram_reported_total > 0:
    # Utiliser le nombre r√©el d'Instagram comme r√©f√©rence (GROUND TRUTH)
    completeness_score = round((total_followings / instagram_reported_total) * 100, 2)
    logger.info(f"Score bas√© sur Instagram reported: {total_followings}/{instagram_reported_total} = {completeness_score:.1f}%")
else:
    # Fallback: Utiliser la fonction SQL bas√©e sur l'historique
    cursor.execute("""
        SELECT calculate_completeness_score(%s, %s)
    """, (target_account, total_followings))
    completeness_score = cursor.fetchone()[0] or 100.0
```

### üí° Avantages

| Crit√®re | Avant (historique) | Apr√®s (Instagram reported) |
|---------|-------------------|---------------------------|
| **Pr√©cision** | ¬±5% (bas√© sur max historique) | **100% pr√©cis** (valeur r√©elle Instagram) |
| **Nouveaux comptes** | Impossible (pas d'historique) | ‚úÖ Fonctionne d√®s le 1er scraping |
| **Croissance rapide** | Score faussement bas | ‚úÖ Score exact |
| **Fiabilit√©** | D√©pend de l'historique | ‚úÖ Ground truth Instagram |

### üìà Exemple concret

**Compte mariadlaura - 25/11/2025** :

```
Instagram affiche: 665 suivi(e)s
Scrap√©: 650 followings (1√®re passe)

Score de compl√©tude = (650 / 665) √ó 100 = 97.74% ‚úÖ
```

Sans l'extraction automatique, le score aurait √©t√© calcul√© par rapport au max historique (moins pr√©cis).

### üîç V√©rification dans la base de donn√©es

```sql
SELECT
    target_account,
    scraping_date,
    total_followings,
    instagram_reported_total,
    completeness_score,
    CASE
        WHEN instagram_reported_total IS NOT NULL
        THEN '‚úÖ Score bas√© sur Instagram'
        ELSE '‚ö†Ô∏è Score bas√© sur historique'
    END as score_method
FROM scraping_metadata
WHERE target_account = 'mariadlaura'
ORDER BY scraping_date DESC
LIMIT 5;
```

**R√©sultat attendu** :
```
 target_account | scraping_date | total_followings | instagram_reported_total | completeness_score | score_method
----------------+---------------+------------------+--------------------------+--------------------+-----------------------------
 mariadlaura    | 2025-11-25    | 650              | 665                      | 97.74              | ‚úÖ Score bas√© sur Instagram
 mariadlaura    | 2025-11-24    | 651              | 665                      | 97.89              | ‚úÖ Score bas√© sur Instagram
 mariadlaura    | 2025-11-23    | 505              | NULL                     | 76.10              | ‚ö†Ô∏è Score bas√© sur historique
```
